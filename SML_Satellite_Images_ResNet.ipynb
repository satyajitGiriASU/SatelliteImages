{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SML_Satellite_Images_ResNet.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JVpeyGlPV48v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this project we show different architectures for deep learning that will help us classify satellite images. In our first part of the project we show how to preprocess the data, tackle data imbalance, and use two common techniques in deep learning to train our model (transfered learning and feature extraction)."
      ]
    },
    {
      "metadata": {
        "id": "1ZilLEvNWDAn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting up the Google Collab Environment\n",
        "\n",
        "We use the following dependenicies in our code:\n",
        "1. Pytorch: For implementing deep learning solutions.\n",
        "2. Matplotlib: For data visualiztion\n",
        "3. CV2: For visualizing images\n",
        "4. Sklearn: For machine learning solutions\n",
        "5. Numpy: For matrix manipulations"
      ]
    },
    {
      "metadata": {
        "id": "Y0io3qvfWoyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "metadata": {
        "id": "EE6kpZJLVVzL",
        "colab_type": "code",
        "outputId": "47f59247-6850-4c31-ded4-0aa1311be2c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import sklearn.svm\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from os.path import exists\n",
        "\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "print(\"Accelerator type = \",accelerator)\n",
        "print(\"Pytorch verision: \", torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Accelerator type = ', 'cu100')\n",
            "('Pytorch verision: ', '1.0.1.post2')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gBGOiGdtW7vH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing the data**\n",
        "\n",
        "Google Collab is an exciting addition to the Machine Learning community. Using google collab, anyone can use GPUs to train their model. What we do here is is mount our google drive into our collab environment so that we can access all of our folder."
      ]
    },
    {
      "metadata": {
        "id": "hJzzZSk8WzNq",
        "colab_type": "code",
        "outputId": "c7511c93-bbaa-4709-d0eb-6004289dddee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TfTho0IuXKtp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check if the data has been loaded to the Google Collab Environment**"
      ]
    },
    {
      "metadata": {
        "id": "aOmisOkyXHS7",
        "colab_type": "code",
        "outputId": "e0b3e673-5066-4adf-ef2e-f90c75b4e646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "cell_type": "code",
      "source": [
        "a = cv2.imread(\"/content/drive/My Drive/ComputerVision/Test/data/test/1/31.jpg\")\n",
        "a = a[...,::-1]\n",
        "plt.imshow(a)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFMCAYAAABCsp4mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQggRQIulEEIE+L/zGMbOTh2KfgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2GgFfvfzXtl_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting Up Pytorch Environment"
      ]
    },
    {
      "metadata": {
        "id": "_tP4-nUHq3U8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to proprocess the image before passing it throught the model for training. These are the preprocessing steps:\n",
        "1. *Resize:* The resnet requires an input image size to be (224, 224) so we first rescale the image. \n",
        "2. *Convert to Tensor*: The Pytorch uses a data class called Tensor. We have to convert from our numpy array to this data type.\n",
        "3. *Batch Normalize:* Since we will be using batch stochastic gradient descent (the computer memory can't load the entire dataset in one instance), we need to normalize all imagize based on the mean and standard deviation across the batch to [0.485,0.456,0.406] and [.229, .224, .225] respectively."
      ]
    },
    {
      "metadata": {
        "id": "XVcZsmIWX2X_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(data_dir):\n",
        "\n",
        "    #Pre processing the data\n",
        "    normalize = transforms.Normalize(mean = [0.485,0.456,0.406],\n",
        "                                    std = [0.229,0.224,0.225])\n",
        "    resize = transforms.Resize((224,224))\n",
        "\n",
        "    preprocessor = transforms.Compose([\n",
        "                                        resize,\n",
        "                                        transforms.ToTensor(),\n",
        "                                        normalize])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.ImageFolder(os.path.join(data_dir,'train'),preprocessor),\n",
        "        batch_size=50,\n",
        "        shuffle = True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.ImageFolder(os.path.join(data_dir,'test'),preprocessor),\n",
        "        batch_size=50,\n",
        "        shuffle = True)\n",
        "\n",
        "    return train_loader, test_loader, len(os.listdir(os.path.join(data_dir,'train')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3YbWZudosNQP",
        "colab_type": "code",
        "outputId": "c218dc1b-6b45-415e-f0a4-ad844642bf2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "trainloader, testloader, num_classes = get_data(\"/content/drive/My Drive/ComputerVision/OneConcern/data\")\n",
        "print(\"Number of classes:\", num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of classes:', 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FnTBDXa2s9pC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading the Model**\n",
        "\n",
        "1.  *Model choice: * this iteration we use a ResNet-18 model. A ResNet model is known for it's skip connections that enables the model to learn identity functions for particular steps thus enabling a deep model to still converge.\n",
        "2. *Transferred Learning: * Since we don't have the hardware capacity to train a deep model from scratch we will only train the last layer. \n",
        "3. *Loss Function: * Since it's an object classification problem, with think the cross entropy equation will serve as a good loss function. \n",
        "4. *Optimizer: * We used a stochastic gradient descent for our first iteration, but would prefer to switch to Adam Optimizer for a later iteration."
      ]
    },
    {
      "metadata": {
        "id": "MjamJpOysrRJ",
        "colab_type": "code",
        "outputId": "50a82f64-89a0-48f0-8045-b20a3382843c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        }
      },
      "cell_type": "code",
      "source": [
        "gpu_flag = torch.cuda.is_available()\n",
        "\n",
        "#preloading Resnet18\n",
        "model = models.resnet18(pretrained = True)\n",
        "\n",
        "#append a new last layer\n",
        "model.fc = nn.Linear(512,num_classes)\n",
        "\n",
        "# define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# setup SGD\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.004, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer,5,.3)\n",
        "\n",
        "#Pre processing the data\n",
        "normalize = transforms.Normalize(mean = [0.485,0.456,0.406], std = [0.229,0.224,0.225])\n",
        "resize = transforms.Resize((224,224))\n",
        "\n",
        "preprocessor = transforms.Compose([resize,transforms.ToTensor(),normalize])\n",
        "\n",
        "\n",
        "gpu_flag = torch.cuda.is_available()\n",
        "print(gpu_flag)\n",
        "if gpu_flag:\n",
        "    model = model.cuda()\n",
        "    \n",
        "print model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fg1K7CnwvDsY",
        "colab_type": "code",
        "outputId": "42e49b18-cec4-47ef-ec0f-7d96db34baa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if gpu_flag:\n",
        "  print(\"We have gpu!\")\n",
        "  model = model.cuda()\n",
        "  criterion = criterion.cuda()\n",
        "\n",
        "epochs = 10\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_acc = 0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have gpu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "odOPOxCnwPeS",
        "colab_type": "code",
        "outputId": "725daa8d-4a10-42be-a1d4-2fd0f3f3d9ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5645
        }
      },
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "test_loss = []\n",
        "accuracy = []\n",
        "\n",
        "for e in range(epochs):\n",
        "      exp_lr_scheduler.step()\n",
        "    \n",
        "      #put model in training mode\n",
        "      model.train()\n",
        "      avg_loss = 0\n",
        "\n",
        "      for i, (x,y) in enumerate(trainloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if gpu_flag:\n",
        "                  x_var = Variable(x).cuda()\n",
        "                  y_actual = Variable(y).cuda()\n",
        "            else:\n",
        "                  x_var = Variable(x)\n",
        "                  y_actual = Variable(y)\n",
        "\n",
        "            y_pred = model.forward(x_var)\n",
        "            loss = criterion(y_pred,y_actual)\n",
        "            loss.backward()\n",
        "            \n",
        "            if(i%10 == 0):\n",
        "                  print(i, loss.item())\n",
        "            avg_loss+=loss.item()\n",
        "            optimizer.step()\n",
        "            \n",
        "      print(\"Done Training\")\n",
        "      train_loss.append(avg_loss*1.0/(i+1))\n",
        "      \n",
        "      #set model in evaluation mode\n",
        "      model.eval()\n",
        "      avg_loss = 0\n",
        "      correct_pred = 0\n",
        "      total_pred = 0\n",
        "      \n",
        "      for i, (x_test,y_test) in enumerate(testloader):\n",
        "\n",
        "          if gpu_flag:\n",
        "              x_test_var = Variable(x_test).cuda()\n",
        "              y_test_var = Variable(y_test).cuda()\n",
        "          else:\n",
        "              x_test_var = Variable(x_test)\n",
        "              y_test_var = Variable(y_test)\n",
        "\n",
        "          y_pred_test = model.forward(x_test_var)\n",
        "          loss = criterion(y_pred_test,y_test_var)\n",
        "          avg_loss+=loss.item()\n",
        "          vals, y_pred = torch.max(y_pred_test,1)\n",
        "\n",
        "          correct_pred += (y_pred.cpu().data.numpy()==y_test_var.cpu().data.numpy()).sum()\n",
        "          total_pred += len(y_pred_test.cpu())\n",
        "      \n",
        "      test_loss.append(avg_loss*1.0/i)\n",
        "      accuracy.append(correct_pred*100.0/total_pred)\n",
        "      print(\"Epoch: \", e, \"Train Loss: \", train_loss[-1], \"Test Loss: \", test_loss[-1], \"Accuracy: \", accuracy[-1])\n",
        "      \n",
        "      #replace model saved \n",
        "      if accuracy[-1]>best_acc:\n",
        "          best_acc = accuracy[-1]\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\n",
        "          model.load_state_dict(best_model_wts)\n",
        "          torch.save(model,'/content/drive/My Drive/ComputerVision/OneConcern/best_finetune.pt')\n",
        "          print(\"Saved model with accuracy: \", best_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 0.02078286185860634)\n",
            "(10, 0.03140169009566307)\n",
            "(20, 0.046105872839689255)\n",
            "(30, 0.018269214779138565)\n",
            "(40, 0.07951486110687256)\n",
            "(50, 0.09838642925024033)\n",
            "(60, 0.1907305121421814)\n",
            "(70, 0.0900983065366745)\n",
            "(80, 0.055307578295469284)\n",
            "(90, 0.10102881491184235)\n",
            "(100, 0.13847710192203522)\n",
            "(110, 0.10576970875263214)\n",
            "(120, 0.07687371224164963)\n",
            "(130, 0.03667012229561806)\n",
            "(140, 0.10552529245615005)\n",
            "(150, 0.04405132681131363)\n",
            "(160, 0.09697481989860535)\n",
            "(170, 0.05469506233930588)\n",
            "(180, 0.02870185859501362)\n",
            "(190, 0.0691099613904953)\n",
            "(200, 0.07347388565540314)\n",
            "(210, 0.064165860414505)\n",
            "(220, 0.09556248784065247)\n",
            "(230, 0.07088238000869751)\n",
            "(240, 0.07585029304027557)\n",
            "(250, 0.17519958317279816)\n",
            "(260, 0.13710592687129974)\n",
            "(270, 0.05090971291065216)\n",
            "(280, 0.06478855013847351)\n",
            "(290, 0.019459610804915428)\n",
            "(300, 0.01304483413696289)\n",
            "Done Training\n",
            "('Epoch: ', 0, 'Train Loss: ', 0.07815007705687511, 'Test Loss: ', 0.10564717385530858, 'Accuracy: ', 96.7599792638673)\n",
            "('Saved model with accuracy: ', 96.7599792638673)\n",
            "(0, 0.030155658721923828)\n",
            "(10, 0.04747342690825462)\n",
            "(20, 0.11862681061029434)\n",
            "(30, 0.01864737458527088)\n",
            "(40, 0.03532026335597038)\n",
            "(50, 0.031342800706624985)\n",
            "(60, 0.024902019649744034)\n",
            "(70, 0.007760286331176758)\n",
            "(80, 0.012156572192907333)\n",
            "(90, 0.026002932339906693)\n",
            "(100, 0.05299556627869606)\n",
            "(110, 0.08474183082580566)\n",
            "(120, 0.012265205383300781)\n",
            "(130, 0.13727062940597534)\n",
            "(140, 0.009843893349170685)\n",
            "(150, 0.015236368402838707)\n",
            "(160, 0.04635258764028549)\n",
            "(170, 0.029904546216130257)\n",
            "(180, 0.011945619247853756)\n",
            "(190, 0.01613280363380909)\n",
            "(200, 0.018820172175765038)\n",
            "(210, 0.041467227041721344)\n",
            "(220, 0.06156038120388985)\n",
            "(230, 0.045959100127220154)\n",
            "(240, 0.15766815841197968)\n",
            "(250, 0.01051389705389738)\n",
            "(260, 0.07786457985639572)\n",
            "(270, 0.031135357916355133)\n",
            "(280, 0.03302212804555893)\n",
            "(290, 0.10842347890138626)\n",
            "(300, 0.03263982757925987)\n",
            "Done Training\n",
            "('Epoch: ', 1, 'Train Loss: ', 0.04406417777210257, 'Test Loss: ', 0.08359113851465381, 'Accuracy: ', 97.01918092275791)\n",
            "('Saved model with accuracy: ', 97.01918092275791)\n",
            "(0, 0.018713627010583878)\n",
            "(10, 0.008441495709121227)\n",
            "(20, 0.01348988525569439)\n",
            "(30, 0.03725482150912285)\n",
            "(40, 0.05194924399256706)\n",
            "(50, 0.024366512894630432)\n",
            "(60, 0.01639062911272049)\n",
            "(70, 0.01021562609821558)\n",
            "(80, 0.010153408162295818)\n",
            "(90, 0.01601872406899929)\n",
            "(100, 0.01181371696293354)\n",
            "(110, 0.04019520804286003)\n",
            "(120, 0.00795543659478426)\n",
            "(130, 0.01126363780349493)\n",
            "(140, 0.0396587960422039)\n",
            "(150, 0.052452705800533295)\n",
            "(160, 0.002036924473941326)\n",
            "(170, 0.07335653156042099)\n",
            "(180, 0.03471117839217186)\n",
            "(190, 0.008969440124928951)\n",
            "(200, 0.09009372442960739)\n",
            "(210, 0.030986238270998)\n",
            "(220, 0.07019282132387161)\n",
            "(230, 0.007814531214535236)\n",
            "(240, 0.07889379560947418)\n",
            "(250, 0.009287777356803417)\n",
            "(260, 0.032860126346349716)\n",
            "(270, 0.049136485904455185)\n",
            "(280, 0.03886152431368828)\n",
            "(290, 0.004901199135929346)\n",
            "(300, 0.020270071923732758)\n",
            "Done Training\n",
            "('Epoch: ', 2, 'Train Loss: ', 0.03162331415738151, 'Test Loss: ', 0.07095966685877798, 'Accuracy: ', 97.38206324520478)\n",
            "('Saved model with accuracy: ', 97.38206324520478)\n",
            "(0, 0.009881124831736088)\n",
            "(10, 0.03261483088135719)\n",
            "(20, 0.022006502375006676)\n",
            "(30, 0.0347827784717083)\n",
            "(40, 0.006770639214664698)\n",
            "(50, 0.0015831660712137818)\n",
            "(60, 0.002695760689675808)\n",
            "(70, 0.04451978579163551)\n",
            "(80, 0.011217155493795872)\n",
            "(90, 0.02636053040623665)\n",
            "(100, 0.005207605194300413)\n",
            "(110, 0.016051549464464188)\n",
            "(120, 0.003774309065192938)\n",
            "(130, 0.008889589458703995)\n",
            "(140, 0.010184526443481445)\n",
            "(150, 0.004399843048304319)\n",
            "(160, 0.009844961576163769)\n",
            "(170, 0.004833841230720282)\n",
            "(180, 0.0008325958042405546)\n",
            "(190, 0.01295018196105957)\n",
            "(200, 0.018069706857204437)\n",
            "(210, 0.0034864903427660465)\n",
            "(220, 0.02750135399401188)\n",
            "(230, 0.009212073870003223)\n",
            "(240, 0.0020747948437929153)\n",
            "(250, 0.010938110761344433)\n",
            "(260, 0.00806036964058876)\n",
            "(270, 0.01811976358294487)\n",
            "(280, 0.016996068879961967)\n",
            "(290, 0.0335233211517334)\n",
            "(300, 0.008184108883142471)\n",
            "Done Training\n",
            "('Epoch: ', 3, 'Train Loss: ', 0.01440309343010362, 'Test Loss: ', 0.060740743431129625, 'Accuracy: ', 98.31518921721099)\n",
            "('Saved model with accuracy: ', 98.31518921721099)\n",
            "(0, 0.0012809943873435259)\n",
            "(10, 0.0013819598825648427)\n",
            "(20, 0.009818906895816326)\n",
            "(30, 0.006425065919756889)\n",
            "(40, 0.013593883253633976)\n",
            "(50, 0.014584388583898544)\n",
            "(60, 0.004612560383975506)\n",
            "(70, 0.0027476786635816097)\n",
            "(80, 0.01093275099992752)\n",
            "(90, 0.03510201349854469)\n",
            "(100, 0.005192613694816828)\n",
            "(110, 0.0025986861437559128)\n",
            "(120, 0.030379991978406906)\n",
            "(130, 0.009344330057501793)\n",
            "(140, 0.00483562471345067)\n",
            "(150, 0.006729984190315008)\n",
            "(160, 0.014167594723403454)\n",
            "(170, 0.0009488106006756425)\n",
            "(180, 0.013396206311881542)\n",
            "(190, 0.003638467751443386)\n",
            "(200, 0.0031965638045221567)\n",
            "(210, 0.01600329391658306)\n",
            "(220, 0.013014964759349823)\n",
            "(230, 0.005369262769818306)\n",
            "(240, 0.009002313949167728)\n",
            "(250, 0.03294357284903526)\n",
            "(260, 0.003018703544512391)\n",
            "(270, 0.0005557441618293524)\n",
            "(280, 0.008747119456529617)\n",
            "(290, 0.005076246336102486)\n",
            "(300, 0.0076385498978197575)\n",
            "Done Training\n",
            "('Epoch: ', 4, 'Train Loss: ', 0.009522800757640122, 'Test Loss: ', 0.05541938042885007, 'Accuracy: ', 98.28926905132192)\n",
            "(0, 0.055294159799814224)\n",
            "(10, 0.021567802876234055)\n",
            "(20, 0.03129565343260765)\n",
            "(30, 0.0011146164033561945)\n",
            "(40, 0.008022203110158443)\n",
            "(50, 0.008509550243616104)\n",
            "(60, 0.0014037418877705932)\n",
            "(70, 0.0010199642274528742)\n",
            "(80, 0.03221186622977257)\n",
            "(90, 0.0017860508523881435)\n",
            "(100, 0.0027417372912168503)\n",
            "(110, 0.004139842931181192)\n",
            "(120, 0.0007880592602305114)\n",
            "(130, 0.008535528555512428)\n",
            "(140, 0.006465492304414511)\n",
            "(150, 0.003583459882065654)\n",
            "(160, 0.0035064697731286287)\n",
            "(170, 0.0004785728524439037)\n",
            "(180, 0.002632942283526063)\n",
            "(190, 0.009297704324126244)\n",
            "(200, 0.005246066953986883)\n",
            "(210, 0.003480443963780999)\n",
            "(220, 0.001047220197506249)\n",
            "(230, 0.001106958370655775)\n",
            "(240, 0.0018240261124446988)\n",
            "(250, 0.010658702813088894)\n",
            "(260, 0.001382694230414927)\n",
            "(270, 0.015141916461288929)\n",
            "(280, 0.014790878631174564)\n",
            "(290, 0.005341425072401762)\n",
            "(300, 0.0031828880310058594)\n",
            "Done Training\n",
            "('Epoch: ', 5, 'Train Loss: ', 0.006599642534067396, 'Test Loss: ', 0.05481702738438503, 'Accuracy: ', 98.34110938310005)\n",
            "('Saved model with accuracy: ', 98.34110938310005)\n",
            "(0, 0.0021450710482895374)\n",
            "(10, 0.003605098696425557)\n",
            "(20, 0.0030683516524732113)\n",
            "(30, 0.0014133835211396217)\n",
            "(40, 0.036224059760570526)\n",
            "(50, 0.0070868683978915215)\n",
            "(60, 0.005504484288394451)\n",
            "(70, 0.001583366421982646)\n",
            "(80, 0.01318857166916132)\n",
            "(90, 0.0024242878425866365)\n",
            "(100, 0.003569202497601509)\n",
            "(110, 0.0016513728769496083)\n",
            "(120, 0.004453468136489391)\n",
            "(130, 0.001366148004308343)\n",
            "(140, 0.002799415495246649)\n",
            "(150, 0.0006271743914112449)\n",
            "(160, 0.0009127044468186796)\n",
            "(170, 0.003318080911412835)\n",
            "(180, 0.0034412003587931395)\n",
            "(190, 0.0011720084585249424)\n",
            "(200, 0.0013734054518863559)\n",
            "(210, 0.0024458980187773705)\n",
            "(220, 0.003258180571720004)\n",
            "(230, 0.0006702422979287803)\n",
            "(240, 0.0020530796609818935)\n",
            "(250, 0.013132624328136444)\n",
            "(260, 0.004315071273595095)\n",
            "(270, 0.001270837732590735)\n",
            "(280, 0.004001026041805744)\n",
            "(290, 0.0018714332254603505)\n",
            "(300, 0.002061119070276618)\n",
            "Done Training\n",
            "('Epoch: ', 6, 'Train Loss: ', 0.006232536600094174, 'Test Loss: ', 0.05574549371059137, 'Accuracy: ', 98.08190772420943)\n",
            "(0, 0.0038608266040682793)\n",
            "(10, 0.004747867584228516)\n",
            "(20, 0.0006363678257912397)\n",
            "(30, 0.0082226088270545)\n",
            "(40, 0.00192315096501261)\n",
            "(50, 0.013520059175789356)\n",
            "(60, 0.002694463822990656)\n",
            "(70, 0.005560245364904404)\n",
            "(80, 0.10544958710670471)\n",
            "(90, 0.002095842268317938)\n",
            "(100, 0.0037838935386389494)\n",
            "(110, 0.005283451173454523)\n",
            "(120, 0.0012571238912642002)\n",
            "(130, 0.0038917541969567537)\n",
            "(140, 0.0009113979176618159)\n",
            "(150, 0.0007988643483258784)\n",
            "(160, 0.027586154639720917)\n",
            "(170, 0.0016546535771340132)\n",
            "(180, 0.001692123361863196)\n",
            "(190, 0.002133855829015374)\n",
            "(200, 0.010266399011015892)\n",
            "(210, 0.002436084672808647)\n",
            "(220, 0.010978231206536293)\n",
            "(230, 0.002533397637307644)\n",
            "(240, 0.0017270755488425493)\n",
            "(250, 0.006275024265050888)\n",
            "(260, 0.019169902428984642)\n",
            "(270, 0.001031198538839817)\n",
            "(280, 0.0012668800773099065)\n",
            "(290, 0.0017966270679607987)\n",
            "(300, 0.0007122039678506553)\n",
            "Done Training\n",
            "('Epoch: ', 7, 'Train Loss: ', 0.005987660104049442, 'Test Loss: ', 0.0535522083420754, 'Accuracy: ', 98.13374805598755)\n",
            "(0, 0.009553899988532066)\n",
            "(10, 0.0010339546715840697)\n",
            "(20, 0.004302797373384237)\n",
            "(30, 0.011363220401108265)\n",
            "(40, 0.003696231869980693)\n",
            "(50, 0.0034355639945715666)\n",
            "(60, 0.006714048329740763)\n",
            "(70, 0.002376022282987833)\n",
            "(80, 0.0008773994632065296)\n",
            "(90, 0.004141616635024548)\n",
            "(100, 0.000498332956340164)\n",
            "(110, 0.0008501053089275956)\n",
            "(120, 0.001277599367313087)\n",
            "(130, 0.0018464660970494151)\n",
            "(140, 0.030379829928278923)\n",
            "(150, 0.002808208577334881)\n",
            "(160, 0.015840472653508186)\n",
            "(170, 0.002990016946569085)\n",
            "(180, 0.009277243167161942)\n",
            "(190, 0.0011827659327536821)\n",
            "(200, 0.001382961287163198)\n",
            "(210, 0.002225723350420594)\n",
            "(220, 0.004122581332921982)\n",
            "(230, 0.002434043912217021)\n",
            "(240, 0.0021724796388298273)\n",
            "(250, 0.0036381911486387253)\n",
            "(260, 0.002086954191327095)\n",
            "(270, 0.0018928813515231013)\n",
            "(280, 0.0020347596146166325)\n",
            "(290, 0.0006380462436936796)\n",
            "(300, 0.0067647360265254974)\n",
            "Done Training\n",
            "('Epoch: ', 8, 'Train Loss: ', 0.004149054393359132, 'Test Loss: ', 0.05386036847772488, 'Accuracy: ', 98.28926905132192)\n",
            "(0, 0.00511277187615633)\n",
            "(10, 0.0010353183606639504)\n",
            "(20, 0.0020298766903579235)\n",
            "(30, 0.015621013939380646)\n",
            "(40, 0.003239326411858201)\n",
            "(50, 0.0006784916040487587)\n",
            "(60, 0.001345834694802761)\n",
            "(70, 0.0003610420098993927)\n",
            "(80, 0.006826315075159073)\n",
            "(90, 0.0011616325937211514)\n",
            "(100, 0.0004207229649182409)\n",
            "(110, 0.004396209493279457)\n",
            "(120, 0.006710300222039223)\n",
            "(130, 0.001137695275247097)\n",
            "(140, 0.011646385304629803)\n",
            "(150, 0.010640859603881836)\n",
            "(160, 0.0003165244997944683)\n",
            "(170, 0.0022654342465102673)\n",
            "(180, 0.0014720344915986061)\n",
            "(190, 0.01642882265150547)\n",
            "(200, 0.005705986171960831)\n",
            "(210, 0.014154195785522461)\n",
            "(220, 0.0011483669513836503)\n",
            "(230, 0.0005386352422647178)\n",
            "(240, 0.003566865809261799)\n",
            "(250, 0.001284418161958456)\n",
            "(260, 0.0016990185249596834)\n",
            "(270, 0.010138311423361301)\n",
            "(280, 0.010788220912218094)\n",
            "(290, 0.0050666905008256435)\n",
            "(300, 0.005390367470681667)\n",
            "Done Training\n",
            "('Epoch: ', 9, 'Train Loss: ', 0.004117508538475736, 'Test Loss: ', 0.05626762856339262, 'Accuracy: ', 98.26334888543286)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8su8aJguwS9q",
        "colab_type": "code",
        "outputId": "51574990-ee71-4967-8075-21157c907d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "list_epochs = [i+1 for i in range(10)]\n",
        "\n",
        "plt.plot(list_epochs,accuracy)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Resnet-18 Accuracy vs. Accuracy')\n",
        "plt.show()\n",
        "plt.plot(list_epochs,train_loss,label='Train Loss')\n",
        "plt.plot(list_epochs,test_loss,label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2dced55dcabb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Hh8Jb9m1Ms9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}