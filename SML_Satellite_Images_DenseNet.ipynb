{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SML_Satellite_Images_DenseNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JVpeyGlPV48v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this project we show different architectures for deep learning that will help us classify satellite images. In our first part of the project we show how to preprocess the data, tackle data imbalance, and use two common techniques in deep learning to train our model (transfered learning and feature extraction)."
      ]
    },
    {
      "metadata": {
        "id": "1ZilLEvNWDAn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting up the Google Collab Environment\n",
        "\n",
        "We use the following dependenicies in our code:\n",
        "1. Pytorch: For implementing deep learning solutions.\n",
        "2. Matplotlib: For data visualiztion\n",
        "3. CV2: For visualizing images\n",
        "4. Sklearn: For machine learning solutions\n",
        "5. Numpy: For matrix manipulations"
      ]
    },
    {
      "metadata": {
        "id": "Y0io3qvfWoyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "metadata": {
        "id": "EE6kpZJLVVzL",
        "colab_type": "code",
        "outputId": "a1d43641-832f-46c9-ad35-bcb61096c205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import sklearn.svm\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from os.path import exists\n",
        "\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "print(\"Accelerator type = \",accelerator)\n",
        "print(\"Pytorch verision: \", torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Accelerator type = ', 'cu100')\n",
            "('Pytorch verision: ', '1.0.1.post2')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gBGOiGdtW7vH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing the data**\n",
        "\n",
        "Google Collab is an exciting addition to the Machine Learning community. Using google collab, anyone can use GPUs to train their model. What we do here is is mount our google drive into our collab environment so that we can access all of our folder."
      ]
    },
    {
      "metadata": {
        "id": "hJzzZSk8WzNq",
        "colab_type": "code",
        "outputId": "043dab63-1930-4fd5-c2a7-6f10d0b06851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TfTho0IuXKtp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check if the data has been loaded to the Google Collab Environment**"
      ]
    },
    {
      "metadata": {
        "id": "aOmisOkyXHS7",
        "colab_type": "code",
        "outputId": "2749fea3-5610-4009-867f-d4c6881233f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "a = cv2.imread(\"/content/drive/My Drive/ComputerVision/Test/data/test/1/31.jpg\")\n",
        "a = a[...,::-1]\n",
        "plt.imshow(a)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2GgFfvfzXtl_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting Up Pytorch Environment"
      ]
    },
    {
      "metadata": {
        "id": "_tP4-nUHq3U8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to proprocess the image before passing it throught the model for training. These are the preprocessing steps:\n",
        "1. *Resize:* The resnet requires an input image size to be (224, 224) so we first rescale the image. \n",
        "2. *Convert to Tensor*: The Pytorch uses a data class called Tensor. We have to convert from our numpy array to this data type.\n",
        "3. *Batch Normalize:* Since we will be using batch stochastic gradient descent (the computer memory can't load the entire dataset in one instance), we need to normalize all imagize based on the mean and standard deviation across the batch to [0.485,0.456,0.406] and [.229, .224, .225] respectively."
      ]
    },
    {
      "metadata": {
        "id": "XVcZsmIWX2X_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(data_dir):\n",
        "\n",
        "    #Pre processing the data\n",
        "    normalize = transforms.Normalize(mean = [0.485,0.456,0.406],\n",
        "                                    std = [0.229,0.224,0.225])\n",
        "    resize = transforms.Resize((224,224))\n",
        "\n",
        "    preprocessor = transforms.Compose([\n",
        "                                        resize,\n",
        "                                        transforms.ToTensor(),\n",
        "                                        normalize])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.ImageFolder(os.path.join(data_dir,'train'),preprocessor),\n",
        "        batch_size=20,\n",
        "        shuffle = True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.ImageFolder(os.path.join(data_dir,'test'),preprocessor),\n",
        "        batch_size=20,\n",
        "        shuffle = True)\n",
        "\n",
        "    return train_loader, test_loader, len(os.listdir(os.path.join(data_dir,'train')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3YbWZudosNQP",
        "colab_type": "code",
        "outputId": "0253d822-c204-4b5f-9cd2-ea7f9f6484b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "trainloader, testloader, num_classes = get_data(\"/content/drive/My Drive/ComputerVision/OneConcern/data\")\n",
        "print(\"Number of classes:\", num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Number of classes:', 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FnTBDXa2s9pC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading the Model**\n",
        "\n",
        "1.  *Model choice: * this iteration we use a ResNet-18 model. A ResNet model is known for it's skip connections that enables the model to learn identity functions for particular steps thus enabling a deep model to still converge.\n",
        "2. *Transferred Learning: * Since we don't have the hardware capacity to train a deep model from scratch we will only train the last layer. \n",
        "3. *Loss Function: * Since it's an object classification problem, with think the cross entropy equation will serve as a good loss function. \n",
        "4. *Optimizer: * We used a stochastic gradient descent for our first iteration, but would prefer to switch to Adam Optimizer for a later iteration."
      ]
    },
    {
      "metadata": {
        "id": "MjamJpOysrRJ",
        "colab_type": "code",
        "outputId": "4d1d0115-4010-44f9-ea6a-1d11ee474f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8870
        }
      },
      "cell_type": "code",
      "source": [
        "gpu_flag = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "model = models.densenet121(pretrained=True)\n",
        "\n",
        "# Freeze training for all layers\n",
        "for param in model.features.parameters():\n",
        "    param.require_grad = False\n",
        "\n",
        "    \n",
        "num_ftrs = model.classifier.in_features\n",
        "model.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# setup SGD\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "#Pre processing the data\n",
        "normalize = transforms.Normalize(mean = [0.485,0.456,0.406], std = [0.229,0.224,0.225])\n",
        "resize = transforms.Resize((224,224))\n",
        "\n",
        "preprocessor = transforms.Compose([resize,transforms.ToTensor(),normalize])\n",
        "\n",
        "\n",
        "gpu_flag = torch.cuda.is_available()\n",
        "print(gpu_flag)\n",
        "if gpu_flag:\n",
        "    model = model.cuda()\n",
        "    \n",
        "print model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.torch/models/densenet121-a639ec97.pth\n",
            "32342954it [00:01, 18835362.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fg1K7CnwvDsY",
        "colab_type": "code",
        "outputId": "c2c90017-b2f9-4d90-f1d3-2b40bd48ca41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "if gpu_flag:\n",
        "  print(\"We have gpu!\")\n",
        "  model = model.cuda()\n",
        "  criterion = criterion.cuda()\n",
        "\n",
        "epochs = 10\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_acc = 0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have gpu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "odOPOxCnwPeS",
        "colab_type": "code",
        "outputId": "5e8e75ba-d61d-4fef-f18c-6087c4b703a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14220
        }
      },
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "test_loss = []\n",
        "accuracy = []\n",
        "\n",
        "for e in range(epochs):\n",
        "      exp_lr_scheduler.step()\n",
        "    \n",
        "      #put model in training mode\n",
        "      model.train()\n",
        "      avg_loss = 0\n",
        "\n",
        "      for i, (x,y) in enumerate(trainloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if gpu_flag:\n",
        "                  x_var = Variable(x).cuda()\n",
        "                  y_actual = Variable(y).cuda()\n",
        "            else:\n",
        "                  x_var = Variable(x)\n",
        "                  y_actual = Variable(y)\n",
        "\n",
        "            y_pred = model.forward(x_var)\n",
        "            loss = criterion(y_pred,y_actual)\n",
        "            loss.backward()\n",
        "            \n",
        "            if(i%10 == 0):\n",
        "                  print(i, loss.item())\n",
        "            avg_loss+=loss.item()\n",
        "            optimizer.step()\n",
        "            \n",
        "      print(\"Done Training\")\n",
        "      train_loss.append(avg_loss*1.0/(i+1))\n",
        "      \n",
        "      #set model in evaluation mode\n",
        "      model.eval()\n",
        "      avg_loss = 0\n",
        "      correct_pred = 0\n",
        "      total_pred = 0\n",
        "      \n",
        "      for i, (x_test,y_test) in enumerate(testloader):\n",
        "\n",
        "          if gpu_flag:\n",
        "              x_test_var = Variable(x_test).cuda()\n",
        "              y_test_var = Variable(y_test).cuda()\n",
        "          else:\n",
        "              x_test_var = Variable(x_test)\n",
        "              y_test_var = Variable(y_test)\n",
        "\n",
        "          y_pred_test = model.forward(x_test_var)\n",
        "          loss = criterion(y_pred_test,y_test_var)\n",
        "          avg_loss+=loss.item()\n",
        "          vals, y_pred = torch.max(y_pred_test,1)\n",
        "\n",
        "          correct_pred += (y_pred.cpu().data.numpy()==y_test_var.cpu().data.numpy()).sum()\n",
        "          total_pred += len(y_pred_test.cpu())\n",
        "      \n",
        "      test_loss.append(avg_loss*1.0/i)\n",
        "      accuracy.append(correct_pred*100.0/total_pred)\n",
        "      print(\"Epoch: \", e, \"Train Loss: \", train_loss[-1], \"Test Loss: \", test_loss[-1], \"Accuracy: \", accuracy[-1])\n",
        "      \n",
        "      #replace model saved \n",
        "      if accuracy[-1]>best_acc:\n",
        "          best_acc = accuracy[-1]\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\n",
        "          model.load_state_dict(best_model_wts)\n",
        "          torch.save(model,'/content/drive/My Drive/ComputerVision/OneConcern/best_finetune.pt')\n",
        "          print(\"Saved model with accuracy: \", best_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, 2.44240665435791)\n",
            "(10, 2.096524715423584)\n",
            "(20, 1.612849473953247)\n",
            "(30, 1.0637586116790771)\n",
            "(40, 0.800947368144989)\n",
            "(50, 0.8041674494743347)\n",
            "(60, 0.752956748008728)\n",
            "(70, 0.4187021255493164)\n",
            "(80, 0.24183352291584015)\n",
            "(90, 1.023208737373352)\n",
            "(100, 0.5711675882339478)\n",
            "(110, 0.4987320303916931)\n",
            "(120, 0.5026372075080872)\n",
            "(130, 0.3535606563091278)\n",
            "(140, 0.41657543182373047)\n",
            "(150, 0.1923380196094513)\n",
            "(160, 0.3151765465736389)\n",
            "(170, 0.1697673201560974)\n",
            "(180, 0.3597317636013031)\n",
            "(190, 0.9924603700637817)\n",
            "(200, 0.34207043051719666)\n",
            "(210, 0.2870655655860901)\n",
            "(220, 0.3296695351600647)\n",
            "(230, 0.7547647953033447)\n",
            "(240, 0.23834547400474548)\n",
            "(250, 0.22260057926177979)\n",
            "(260, 0.2304970771074295)\n",
            "(270, 0.5986348986625671)\n",
            "(280, 0.13902747631072998)\n",
            "(290, 0.25216594338417053)\n",
            "(300, 0.36867210268974304)\n",
            "(310, 0.14758151769638062)\n",
            "(320, 0.21218058466911316)\n",
            "(330, 0.14883948862552643)\n",
            "(340, 0.09639616310596466)\n",
            "(350, 0.28183603286743164)\n",
            "(360, 0.15848302841186523)\n",
            "(370, 0.04123532772064209)\n",
            "(380, 0.1720864325761795)\n",
            "(390, 0.3917284309864044)\n",
            "(400, 0.45663565397262573)\n",
            "(410, 0.7217468619346619)\n",
            "(420, 0.16339433193206787)\n",
            "(430, 0.37204408645629883)\n",
            "(440, 0.19124488532543182)\n",
            "(450, 0.17280688881874084)\n",
            "(460, 0.13304974138736725)\n",
            "(470, 0.20351102948188782)\n",
            "(480, 0.4202193319797516)\n",
            "(490, 0.19044983386993408)\n",
            "(500, 0.06363971531391144)\n",
            "(510, 0.4345584511756897)\n",
            "(520, 0.8055672645568848)\n",
            "(530, 0.1546974629163742)\n",
            "(540, 0.361525297164917)\n",
            "(550, 0.10135575383901596)\n",
            "(560, 0.48954325914382935)\n",
            "(570, 0.3128761947154999)\n",
            "(580, 0.08789148181676865)\n",
            "(590, 0.3159381151199341)\n",
            "(600, 0.3053373098373413)\n",
            "(610, 0.11735526472330093)\n",
            "(620, 0.10741724818944931)\n",
            "(630, 0.197035551071167)\n",
            "(640, 0.13087083399295807)\n",
            "(650, 0.3065592050552368)\n",
            "(660, 0.03060917928814888)\n",
            "(670, 0.2155493199825287)\n",
            "(680, 0.3787167966365814)\n",
            "(690, 0.021365022286772728)\n",
            "(700, 0.04074973985552788)\n",
            "(710, 0.04761376231908798)\n",
            "(720, 0.4888085424900055)\n",
            "(730, 0.07749798148870468)\n",
            "(740, 0.2675040364265442)\n",
            "(750, 0.15535981953144073)\n",
            "(760, 0.12055830657482147)\n",
            "(770, 0.1590956747531891)\n",
            "Done Training\n",
            "('Epoch: ', 0, 'Train Loss: ', 0.3739742311259869, 'Test Loss: ', 0.10496921231485128, 'Accuracy: ', 96.47485743908761)\n",
            "('Saved model with accuracy: ', 96.47485743908761)\n",
            "(0, 0.14645202457904816)\n",
            "(10, 0.1859719306230545)\n",
            "(20, 0.03330359607934952)\n",
            "(30, 0.05309123918414116)\n",
            "(40, 0.08490536361932755)\n",
            "(50, 0.2339463233947754)\n",
            "(60, 0.04299507290124893)\n",
            "(70, 0.1645417958498001)\n",
            "(80, 0.13284674286842346)\n",
            "(90, 0.02348926104605198)\n",
            "(100, 0.18998844921588898)\n",
            "(110, 0.1322169005870819)\n",
            "(120, 0.36912959814071655)\n",
            "(130, 0.20959465205669403)\n",
            "(140, 0.05052735656499863)\n",
            "(150, 0.13388825953006744)\n",
            "(160, 0.005883383564651012)\n",
            "(170, 0.11955505609512329)\n",
            "(180, 0.33979061245918274)\n",
            "(190, 0.0806465893983841)\n",
            "(200, 0.04494297504425049)\n",
            "(210, 0.00736689567565918)\n",
            "(220, 0.6087296605110168)\n",
            "(230, 0.0990075096487999)\n",
            "(240, 0.124547079205513)\n",
            "(250, 0.1368512362241745)\n",
            "(260, 0.07156150043010712)\n",
            "(270, 0.09821496158838272)\n",
            "(280, 0.07242212444543839)\n",
            "(290, 0.23202118277549744)\n",
            "(300, 0.018096018582582474)\n",
            "(310, 0.02034435234963894)\n",
            "(320, 0.026342403143644333)\n",
            "(330, 0.11529718339443207)\n",
            "(340, 0.054073117673397064)\n",
            "(350, 0.40331536531448364)\n",
            "(360, 0.2827872633934021)\n",
            "(370, 0.3602255582809448)\n",
            "(380, 0.018871616572141647)\n",
            "(390, 0.4562342166900635)\n",
            "(400, 0.04092419147491455)\n",
            "(410, 0.3174925744533539)\n",
            "(420, 0.011456298641860485)\n",
            "(430, 0.06528420746326447)\n",
            "(440, 0.1952916830778122)\n",
            "(450, 0.2593623399734497)\n",
            "(460, 0.11601867526769638)\n",
            "(470, 0.01552362460643053)\n",
            "(480, 0.022550582885742188)\n",
            "(490, 0.10221199691295624)\n",
            "(500, 0.20973511040210724)\n",
            "(510, 0.11921314895153046)\n",
            "(520, 0.027273083105683327)\n",
            "(530, 0.033708833158016205)\n",
            "(540, 0.1433568298816681)\n",
            "(550, 0.16707809269428253)\n",
            "(560, 0.14528122544288635)\n",
            "(570, 0.07487718760967255)\n",
            "(580, 0.005909776780754328)\n",
            "(590, 0.24666555225849152)\n",
            "(600, 0.06131274625658989)\n",
            "(610, 0.1184663400053978)\n",
            "(620, 0.05776212364435196)\n",
            "(630, 0.02297506295144558)\n",
            "(640, 0.12374912202358246)\n",
            "(650, 0.1932142823934555)\n",
            "(660, 0.037068985402584076)\n",
            "(670, 0.043936587870121)\n",
            "(680, 0.35754817724227905)\n",
            "(690, 0.25824522972106934)\n",
            "(700, 0.04931533336639404)\n",
            "(710, 0.02350790426135063)\n",
            "(720, 0.07131199538707733)\n",
            "(730, 0.03627791255712509)\n",
            "(740, 0.2009737491607666)\n",
            "(750, 0.16486462950706482)\n",
            "(760, 0.03682606294751167)\n",
            "(770, 0.27221208810806274)\n",
            "Done Training\n",
            "('Epoch: ', 1, 'Train Loss: ', 0.13025883320637077, 'Test Loss: ', 0.07533490225978312, 'Accuracy: ', 97.48574390876102)\n",
            "('Saved model with accuracy: ', 97.48574390876102)\n",
            "(0, 0.08277356624603271)\n",
            "(10, 0.09367835521697998)\n",
            "(20, 0.02844364568591118)\n",
            "(30, 0.06876365840435028)\n",
            "(40, 0.09650926291942596)\n",
            "(50, 0.04238853603601456)\n",
            "(60, 0.07546081393957138)\n",
            "(70, 0.10268809646368027)\n",
            "(80, 0.037694238126277924)\n",
            "(90, 0.029403161257505417)\n",
            "(100, 0.25817567110061646)\n",
            "(110, 0.10217107832431793)\n",
            "(120, 0.024499844759702682)\n",
            "(130, 0.00841679610311985)\n",
            "(140, 0.11425240337848663)\n",
            "(150, 0.03961939737200737)\n",
            "(160, 0.01934213563799858)\n",
            "(170, 0.06950382888317108)\n",
            "(180, 0.06157367303967476)\n",
            "(190, 0.04400094598531723)\n",
            "(200, 0.023909712210297585)\n",
            "(210, 0.0348590612411499)\n",
            "(220, 0.0682370662689209)\n",
            "(230, 0.05694713443517685)\n",
            "(240, 0.01751708984375)\n",
            "(250, 0.09945318847894669)\n",
            "(260, 0.04902968555688858)\n",
            "(270, 0.0267515666782856)\n",
            "(280, 0.08673343807458878)\n",
            "(290, 0.13092537224292755)\n",
            "(300, 0.060546230524778366)\n",
            "(310, 0.03443706035614014)\n",
            "(320, 0.035571981221437454)\n",
            "(330, 0.014855027198791504)\n",
            "(340, 0.019938135519623756)\n",
            "(350, 0.04072060436010361)\n",
            "(360, 0.11765778064727783)\n",
            "(370, 0.06903696060180664)\n",
            "(380, 0.01885383203625679)\n",
            "(390, 0.002344846725463867)\n",
            "(400, 0.10892333835363388)\n",
            "(410, 0.11426746845245361)\n",
            "(420, 0.02409336529672146)\n",
            "(430, 0.2283051460981369)\n",
            "(440, 0.06594274193048477)\n",
            "(450, 0.013003945350646973)\n",
            "(460, 0.051691390573978424)\n",
            "(470, 0.2993873357772827)\n",
            "(480, 0.02176048792898655)\n",
            "(490, 0.046277355402708054)\n",
            "(500, 0.008483147248625755)\n",
            "(510, 0.008367514237761497)\n",
            "(520, 0.05619657039642334)\n",
            "(530, 0.00874016247689724)\n",
            "(540, 0.04181218147277832)\n",
            "(550, 0.019816160202026367)\n",
            "(560, 0.16007861495018005)\n",
            "(570, 0.13387294113636017)\n",
            "(580, 0.05045421048998833)\n",
            "(590, 0.21416039764881134)\n",
            "(600, 0.005981731228530407)\n",
            "(610, 0.006835532374680042)\n",
            "(620, 0.06304862350225449)\n",
            "(630, 0.02129654958844185)\n",
            "(640, 0.016664933413267136)\n",
            "(650, 0.12555161118507385)\n",
            "(660, 0.08966958522796631)\n",
            "(670, 0.0838397964835167)\n",
            "(680, 0.03896274417638779)\n",
            "(690, 0.030160069465637207)\n",
            "(700, 0.08317317813634872)\n",
            "(710, 0.2246810644865036)\n",
            "(720, 0.13539375364780426)\n",
            "(730, 0.030149221420288086)\n",
            "(740, 0.1829880177974701)\n",
            "(750, 0.034949541091918945)\n",
            "(760, 0.048862624913454056)\n",
            "(770, 0.019513821229338646)\n",
            "Done Training\n",
            "('Epoch: ', 2, 'Train Loss: ', 0.08369196661088958, 'Test Loss: ', 0.07027084581235006, 'Accuracy: ', 97.66718506998444)\n",
            "('Saved model with accuracy: ', 97.66718506998444)\n",
            "(0, 0.043717242777347565)\n",
            "(10, 0.023020053282380104)\n",
            "(20, 0.014126038178801537)\n",
            "(30, 0.1981063336133957)\n",
            "(40, 0.010164785198867321)\n",
            "(50, 0.0784313902258873)\n",
            "(60, 0.022591710090637207)\n",
            "(70, 0.03679239749908447)\n",
            "(80, 0.032486677169799805)\n",
            "(90, 0.13726183772087097)\n",
            "(100, 0.012868690304458141)\n",
            "(110, 0.00991044007241726)\n",
            "(120, 0.005578923039138317)\n",
            "(130, 0.08709938824176788)\n",
            "(140, 0.07660017162561417)\n",
            "(150, 0.006786680314689875)\n",
            "(160, 0.06596174091100693)\n",
            "(170, 0.050238870084285736)\n",
            "(180, 0.07344035804271698)\n",
            "(190, 0.026890898123383522)\n",
            "(200, 0.016861295327544212)\n",
            "(210, 0.08079123497009277)\n",
            "(220, 0.011045241728425026)\n",
            "(230, 0.1002025157213211)\n",
            "(240, 0.004965567495673895)\n",
            "(250, 0.11608058214187622)\n",
            "(260, 0.012465596199035645)\n",
            "(270, 0.00905451737344265)\n",
            "(280, 0.02272498607635498)\n",
            "(290, 0.044036269187927246)\n",
            "(300, 0.007513380143791437)\n",
            "(310, 0.058992840349674225)\n",
            "(320, 0.03670365735888481)\n",
            "(330, 0.13110551238059998)\n",
            "(340, 0.024289656430482864)\n",
            "(350, 0.0070202588103711605)\n",
            "(360, 0.04000968858599663)\n",
            "(370, 0.11535410583019257)\n",
            "(380, 0.013157844543457031)\n",
            "(390, 0.04196355491876602)\n",
            "(400, 0.12602010369300842)\n",
            "(410, 0.005253100302070379)\n",
            "(420, 0.024252748116850853)\n",
            "(430, 0.03631310537457466)\n",
            "(440, 0.010734891518950462)\n",
            "(450, 0.1584721803665161)\n",
            "(460, 0.01593029499053955)\n",
            "(470, 0.02798941172659397)\n",
            "(480, 0.00237290863879025)\n",
            "(490, 0.0323232039809227)\n",
            "(500, 0.01509249210357666)\n",
            "(510, 0.013917922973632812)\n",
            "(520, 0.006161355879157782)\n",
            "(530, 0.010532069019973278)\n",
            "(540, 0.09956321865320206)\n",
            "(550, 0.026403427124023438)\n",
            "(560, 0.02537095546722412)\n",
            "(570, 0.021640444174408913)\n",
            "(580, 0.005469322204589844)\n",
            "(590, 0.06232774257659912)\n",
            "(600, 0.06874337047338486)\n",
            "(610, 0.003765320871025324)\n",
            "(620, 0.10136927664279938)\n",
            "(630, 0.02670290507376194)\n",
            "(640, 0.0037261724937707186)\n",
            "(650, 0.005831122398376465)\n",
            "(660, 0.4025347828865051)\n",
            "(670, 0.25837641954421997)\n",
            "(680, 0.15524065494537354)\n",
            "(690, 0.01697850227355957)\n",
            "(700, 0.10040242969989777)\n",
            "(710, 0.05454587936401367)\n",
            "(720, 0.07871472835540771)\n",
            "(730, 0.03134756162762642)\n",
            "(740, 0.016951631754636765)\n",
            "(750, 0.05283341556787491)\n",
            "(760, 0.029326224699616432)\n",
            "(770, 0.04437222331762314)\n",
            "Done Training\n",
            "('Epoch: ', 3, 'Train Loss: ', 0.06126132216128336, 'Test Loss: ', 0.06957177737664703, 'Accuracy: ', 97.77086573354069)\n",
            "('Saved model with accuracy: ', 97.77086573354069)\n",
            "(0, 0.021373867988586426)\n",
            "(10, 0.0758616179227829)\n",
            "(20, 0.0121086360886693)\n",
            "(30, 0.01591050624847412)\n",
            "(40, 0.015891337767243385)\n",
            "(50, 0.06849811226129532)\n",
            "(60, 0.024120068177580833)\n",
            "(70, 0.004943919368088245)\n",
            "(80, 0.01557536143809557)\n",
            "(90, 0.1559998095035553)\n",
            "(100, 0.020460844039916992)\n",
            "(110, 0.14384739100933075)\n",
            "(120, 0.009904933162033558)\n",
            "(130, 0.15453338623046875)\n",
            "(140, 0.008197998628020287)\n",
            "(150, 0.03053276613354683)\n",
            "(160, 0.03080301359295845)\n",
            "(170, 0.025009680539369583)\n",
            "(180, 0.0428401455283165)\n",
            "(190, 0.01884152926504612)\n",
            "(200, 0.0064470767974853516)\n",
            "(210, 0.046318769454956055)\n",
            "(220, 0.024857735261321068)\n",
            "(230, 0.40585190057754517)\n",
            "(240, 0.006937789730727673)\n",
            "(250, 0.059734441339969635)\n",
            "(260, 0.049817729741334915)\n",
            "(270, 0.12144958972930908)\n",
            "(280, 0.010744285769760609)\n",
            "(290, 0.05279204994440079)\n",
            "(300, 0.050812460482120514)\n",
            "(310, 0.007793879602104425)\n",
            "(320, 0.15229424834251404)\n",
            "(330, 0.01950383186340332)\n",
            "(340, 0.040238071233034134)\n",
            "(350, 0.009929776191711426)\n",
            "(360, 0.1847204566001892)\n",
            "(370, 0.05827643722295761)\n",
            "(380, 0.029582858085632324)\n",
            "(390, 0.005850768182426691)\n",
            "(400, 0.009588813409209251)\n",
            "(410, 0.0443667396903038)\n",
            "(420, 0.10892057418823242)\n",
            "(430, 0.02527930773794651)\n",
            "(440, 0.014017772860825062)\n",
            "(450, 0.05754814296960831)\n",
            "(460, 0.0033963918685913086)\n",
            "(470, 0.035761356353759766)\n",
            "(480, 0.1027497798204422)\n",
            "(490, 0.11177051067352295)\n",
            "(500, 0.0024240731727331877)\n",
            "(510, 0.028033042326569557)\n",
            "(520, 0.014166712760925293)\n",
            "(530, 0.0018258094787597656)\n",
            "(540, 0.03446383401751518)\n",
            "(550, 0.006017661187797785)\n",
            "(560, 0.005989432334899902)\n",
            "(570, 0.00652811536565423)\n",
            "(580, 0.04288971424102783)\n",
            "(590, 0.01718132570385933)\n",
            "(600, 0.042449306696653366)\n",
            "(610, 0.01625187322497368)\n",
            "(620, 0.032341718673706055)\n",
            "(630, 0.012824535369873047)\n",
            "(640, 0.09054043143987656)\n",
            "(650, 0.03474896028637886)\n",
            "(660, 0.22868147492408752)\n",
            "(670, 0.004910183139145374)\n",
            "(680, 0.007776284124702215)\n",
            "(690, 0.023671651259064674)\n",
            "(700, 0.02109217643737793)\n",
            "(710, 0.010397720150649548)\n",
            "(720, 0.02149367332458496)\n",
            "(730, 0.020728016272187233)\n",
            "(740, 0.012699723243713379)\n",
            "(750, 0.025954198092222214)\n",
            "(760, 0.005543231964111328)\n",
            "(770, 0.0076285600662231445)\n",
            "Done Training\n",
            "('Epoch: ', 4, 'Train Loss: ', 0.04053162047482863, 'Test Loss: ', 0.06628691747088548, 'Accuracy: ', 97.79678589942975)\n",
            "('Saved model with accuracy: ', 97.79678589942975)\n",
            "(0, 0.07989156246185303)\n",
            "(10, 0.06131603568792343)\n",
            "(20, 0.005922532174736261)\n",
            "(30, 0.008288359269499779)\n",
            "(40, 0.04371745511889458)\n",
            "(50, 0.05551338195800781)\n",
            "(60, 0.03845372051000595)\n",
            "(70, 0.18193742632865906)\n",
            "(80, 0.0016482353676110506)\n",
            "(90, 0.0038052320014685392)\n",
            "(100, 0.05330073833465576)\n",
            "(110, 0.015715217217803)\n",
            "(120, 0.01017007790505886)\n",
            "(130, 0.1723114550113678)\n",
            "(140, 0.0238264799118042)\n",
            "(150, 0.010794234462082386)\n",
            "(160, 0.01759641245007515)\n",
            "(170, 0.008978771977126598)\n",
            "(180, 0.011006569489836693)\n",
            "(190, 0.02351958677172661)\n",
            "(200, 0.007855820469558239)\n",
            "(210, 0.004390048794448376)\n",
            "(220, 0.010791254229843616)\n",
            "(230, 0.0027712106239050627)\n",
            "(240, 0.0031729936599731445)\n",
            "(250, 0.29690074920654297)\n",
            "(260, 0.01925518549978733)\n",
            "(270, 0.12159206718206406)\n",
            "(280, 0.00506591796875)\n",
            "(290, 0.002963972045108676)\n",
            "(300, 0.007350826170295477)\n",
            "(310, 0.061756134033203125)\n",
            "(320, 0.01878533326089382)\n",
            "(330, 0.009567499160766602)\n",
            "(340, 0.008529233746230602)\n",
            "(350, 0.3646164536476135)\n",
            "(360, 0.006701993755996227)\n",
            "(370, 0.0023468018043786287)\n",
            "(380, 0.008239006623625755)\n",
            "(390, 0.008403873071074486)\n",
            "(400, 0.009926152415573597)\n",
            "(410, 0.014058470726013184)\n",
            "(420, 0.006690502166748047)\n",
            "(430, 0.018048930913209915)\n",
            "(440, 0.0027331351302564144)\n",
            "(450, 0.005920338444411755)\n",
            "(460, 0.0325549840927124)\n",
            "(470, 0.015827488154172897)\n",
            "(480, 0.04261229187250137)\n",
            "(490, 0.010423135943710804)\n",
            "(500, 0.006972885224968195)\n",
            "(510, 0.0028121948707848787)\n",
            "(520, 0.17067962884902954)\n",
            "(530, 0.1416434943675995)\n",
            "(540, 0.019691800698637962)\n",
            "(550, 0.00724418181926012)\n",
            "(560, 0.006623339839279652)\n",
            "(570, 0.00541577348485589)\n",
            "(580, 0.10329258441925049)\n",
            "(590, 0.00721664447337389)\n",
            "(600, 0.007743239402770996)\n",
            "(610, 0.08072908222675323)\n",
            "(620, 0.005503845401108265)\n",
            "(630, 0.01946120336651802)\n",
            "(640, 0.03698713704943657)\n",
            "(650, 0.0628814697265625)\n",
            "(660, 0.07610563933849335)\n",
            "(670, 0.0036237717140465975)\n",
            "(680, 0.014522242359817028)\n",
            "(690, 0.09059057384729385)\n",
            "(700, 0.005931281950324774)\n",
            "(710, 0.013319754973053932)\n",
            "(720, 0.005500078201293945)\n",
            "(730, 0.0063283443450927734)\n",
            "(740, 0.008444046601653099)\n",
            "(750, 0.027167677879333496)\n",
            "(760, 0.004897761158645153)\n",
            "(770, 0.024535108357667923)\n",
            "Done Training\n",
            "('Epoch: ', 5, 'Train Loss: ', 0.030727875116815847, 'Test Loss: ', 0.10633115813895226, 'Accuracy: ', 96.37117677553137)\n",
            "(0, 0.0062227011658251286)\n",
            "(10, 0.0016160011291503906)\n",
            "(20, 0.113974429666996)\n",
            "(30, 0.0074394466355443)\n",
            "(40, 0.005377769470214844)\n",
            "(50, 0.0016743183368816972)\n",
            "(60, 0.06597654521465302)\n",
            "(70, 0.021472740918397903)\n",
            "(80, 0.014322829432785511)\n",
            "(90, 0.02806851826608181)\n",
            "(100, 0.09140884876251221)\n",
            "(110, 0.009295177645981312)\n",
            "(120, 0.05321945995092392)\n",
            "(130, 0.012994671240448952)\n",
            "(140, 0.05946211889386177)\n",
            "(150, 0.0026684284675866365)\n",
            "(160, 0.058513760566711426)\n",
            "(170, 0.0047454833984375)\n",
            "(180, 0.0017550468910485506)\n",
            "(190, 0.15865926444530487)\n",
            "(200, 0.0330500602722168)\n",
            "(210, 0.010642290115356445)\n",
            "(220, 0.0017896651988849044)\n",
            "(230, 0.000904083251953125)\n",
            "(240, 0.00653839111328125)\n",
            "(250, 0.005331897642463446)\n",
            "(260, 0.010457468219101429)\n",
            "(270, 0.014216423034667969)\n",
            "(280, 0.06992049515247345)\n",
            "(290, 0.0017571926582604647)\n",
            "(300, 0.008757281117141247)\n",
            "(310, 0.0015707493294030428)\n",
            "(320, 0.02158966101706028)\n",
            "(330, 0.022204900160431862)\n",
            "(340, 0.003535795258358121)\n",
            "(350, 0.008503103628754616)\n",
            "(360, 0.007252836134284735)\n",
            "(370, 0.0026571513153612614)\n",
            "(380, 0.004732751753181219)\n",
            "(390, 0.015558051876723766)\n",
            "(400, 0.007777261547744274)\n",
            "(410, 0.0023889541625976562)\n",
            "(420, 0.044617511332035065)\n",
            "(430, 0.02475121058523655)\n",
            "(440, 0.12180354446172714)\n",
            "(450, 0.08408711105585098)\n",
            "(460, 0.010791683569550514)\n",
            "(470, 0.004851961042732)\n",
            "(480, 0.006552410311996937)\n",
            "(490, 0.002688169479370117)\n",
            "(500, 0.00479469308629632)\n",
            "(510, 0.004272031597793102)\n",
            "(520, 0.01847381517291069)\n",
            "(530, 0.010361909866333008)\n",
            "(540, 0.005172634031623602)\n",
            "(550, 0.012841773219406605)\n",
            "(560, 0.010646581649780273)\n",
            "(570, 0.00892262440174818)\n",
            "(580, 0.13819220662117004)\n",
            "(590, 0.006612730212509632)\n",
            "(600, 0.024686813354492188)\n",
            "(610, 0.003091192338615656)\n",
            "(620, 0.004539680667221546)\n",
            "(630, 0.04839608818292618)\n",
            "(640, 0.0023773908615112305)\n",
            "(650, 0.003677320433780551)\n",
            "(660, 0.005326223559677601)\n",
            "(670, 0.003204297972843051)\n",
            "(680, 0.0065871477127075195)\n",
            "(690, 0.04767262935638428)\n",
            "(700, 0.0030650615226477385)\n",
            "(710, 0.02425537072122097)\n",
            "(720, 0.015685033053159714)\n",
            "(730, 0.02763817273080349)\n",
            "(740, 0.0016214370261877775)\n",
            "(750, 0.004736518952995539)\n",
            "(760, 0.0003659248468466103)\n",
            "(770, 0.0068323612213134766)\n",
            "Done Training\n",
            "('Epoch: ', 6, 'Train Loss: ', 0.023205658894036457, 'Test Loss: ', 0.07356392777243552, 'Accuracy: ', 97.4339035769829)\n",
            "(0, 0.0021723031532019377)\n",
            "(10, 0.003698158310726285)\n",
            "(20, 0.03848154470324516)\n",
            "(30, 0.007491088006645441)\n",
            "(40, 0.032338596880435944)\n",
            "(50, 0.000978660536929965)\n",
            "(60, 0.0008794784662313759)\n",
            "(70, 0.053191591054201126)\n",
            "(80, 0.0030811310280114412)\n",
            "(90, 0.03308544307947159)\n",
            "(100, 0.0034096003510057926)\n",
            "(110, 0.013376903720200062)\n",
            "(120, 0.031346868723630905)\n",
            "(130, 0.007990717887878418)\n",
            "(140, 0.0012687206035479903)\n",
            "(150, 0.021796846762299538)\n",
            "(160, 0.005945968441665173)\n",
            "(170, 0.003978562541306019)\n",
            "(180, 0.027388835325837135)\n",
            "(190, 0.007793903350830078)\n",
            "(200, 0.023514818400144577)\n",
            "(210, 0.02785172499716282)\n",
            "(220, 0.033324528485536575)\n",
            "(230, 0.0038438797928392887)\n",
            "(240, 0.008524131961166859)\n",
            "(250, 0.00647890567779541)\n",
            "(260, 0.025957416743040085)\n",
            "(270, 0.027688289061188698)\n",
            "(280, 0.0009546756627969444)\n",
            "(290, 0.001988363219425082)\n",
            "(300, 0.0014927625888958573)\n",
            "(310, 0.009180450811982155)\n",
            "(320, 0.002054834272712469)\n",
            "(330, 0.0019135475158691406)\n",
            "(340, 0.004842519760131836)\n",
            "(350, 0.012120747938752174)\n",
            "(360, 0.10668337345123291)\n",
            "(370, 0.0021491528023034334)\n",
            "(380, 0.0032511234749108553)\n",
            "(390, 0.0027628899551928043)\n",
            "(400, 0.0021441460121423006)\n",
            "(410, 0.006422805599868298)\n",
            "(420, 0.0049574850127100945)\n",
            "(430, 0.001092124031856656)\n",
            "(440, 0.0013654232025146484)\n",
            "(450, 0.003995418548583984)\n",
            "(460, 0.001545000122860074)\n",
            "(470, 0.0014942169655114412)\n",
            "(480, 0.0017895698547363281)\n",
            "(490, 0.005573058035224676)\n",
            "(500, 0.000865936279296875)\n",
            "(510, 0.002993559930473566)\n",
            "(520, 0.03003055974841118)\n",
            "(530, 0.026145290583372116)\n",
            "(540, 0.005342364311218262)\n",
            "(550, 0.01235122699290514)\n",
            "(560, 0.0034842013847082853)\n",
            "(570, 0.04639284685254097)\n",
            "(580, 0.11866722255945206)\n",
            "(590, 0.05070500448346138)\n",
            "(600, 0.00796976126730442)\n",
            "(610, 0.009495067410171032)\n",
            "(620, 0.0017349242698401213)\n",
            "(630, 0.003913831897079945)\n",
            "(640, 0.0014490127796307206)\n",
            "(650, 0.004612159915268421)\n",
            "(660, 0.019647622480988503)\n",
            "(670, 0.0013463974464684725)\n",
            "(680, 0.0026243210304528475)\n",
            "(690, 0.0013396262656897306)\n",
            "(700, 0.027548979967832565)\n",
            "(710, 0.0006889343494549394)\n",
            "(720, 0.009702444076538086)\n",
            "(730, 0.0001954555482370779)\n",
            "(740, 0.0019423484336584806)\n",
            "(750, 0.005861139390617609)\n",
            "(760, 0.02202615700662136)\n",
            "(770, 0.0021657466422766447)\n",
            "Done Training\n",
            "('Epoch: ', 7, 'Train Loss: ', 0.014804850870408004, 'Test Loss: ', 0.05050229952704891, 'Accuracy: ', 98.31518921721099)\n",
            "('Saved model with accuracy: ', 98.31518921721099)\n",
            "(0, 0.0017228126525878906)\n",
            "(10, 0.004751825239509344)\n",
            "(20, 0.0070147039368748665)\n",
            "(30, 0.0068146465346217155)\n",
            "(40, 0.0017082691192626953)\n",
            "(50, 0.006740450859069824)\n",
            "(60, 0.010801315307617188)\n",
            "(70, 0.0028182745445519686)\n",
            "(80, 0.016544055193662643)\n",
            "(90, 0.002730798674747348)\n",
            "(100, 0.006545519921928644)\n",
            "(110, 0.004123878665268421)\n",
            "(120, 0.003086996031925082)\n",
            "(130, 0.010228848084807396)\n",
            "(140, 0.0035744905471801758)\n",
            "(150, 0.019016146659851074)\n",
            "(160, 0.0007760524749755859)\n",
            "(170, 0.0010415554279461503)\n",
            "(180, 0.0021257400512695312)\n",
            "(190, 0.0017826079856604338)\n",
            "(200, 0.08292782306671143)\n",
            "(210, 0.0027201175689697266)\n",
            "(220, 0.007708502002060413)\n",
            "(230, 0.002295327140018344)\n",
            "(240, 0.010859894566237926)\n",
            "(250, 0.0016963959205895662)\n",
            "(260, 0.0007365226629190147)\n",
            "(270, 0.001174879027530551)\n",
            "(280, 0.005542731378227472)\n",
            "(290, 0.006049299146980047)\n",
            "(300, 0.007326317019760609)\n",
            "(310, 0.0012667179107666016)\n",
            "(320, 0.00362396240234375)\n",
            "(330, 0.003150391625240445)\n",
            "(340, 0.011479544453322887)\n",
            "(350, 0.00489232549443841)\n",
            "(360, 0.004728889558464289)\n",
            "(370, 0.12134679406881332)\n",
            "(380, 0.004916572477668524)\n",
            "(390, 0.0016031742561608553)\n",
            "(400, 0.05613696575164795)\n",
            "(410, 0.0029679774306714535)\n",
            "(420, 0.0014438151847571135)\n",
            "(430, 0.007700991816818714)\n",
            "(440, 0.023485207930207253)\n",
            "(450, 0.0038643598090857267)\n",
            "(460, 0.0010111331939697266)\n",
            "(470, 0.09863688796758652)\n",
            "(480, 0.006272268481552601)\n",
            "(490, 0.0007159709930419922)\n",
            "(500, 0.0027820109389722347)\n",
            "(510, 0.020032119005918503)\n",
            "(520, 0.0018774985801428556)\n",
            "(530, 0.00804128684103489)\n",
            "(540, 0.03942210599780083)\n",
            "(550, 0.010500788688659668)\n",
            "(560, 0.0027771710883826017)\n",
            "(570, 0.0015482663875445724)\n",
            "(580, 0.005295944400131702)\n",
            "(590, 0.0019423008197918534)\n",
            "(600, 0.005636477377265692)\n",
            "(610, 0.0030324459075927734)\n",
            "(620, 0.013773488812148571)\n",
            "(630, 0.004926919937133789)\n",
            "(640, 0.0053446292877197266)\n",
            "(650, 0.007751202676445246)\n",
            "(660, 0.001358676003292203)\n",
            "(670, 0.004896354861557484)\n",
            "(680, 0.0668044313788414)\n",
            "(690, 0.00224802503362298)\n",
            "(700, 0.0028565884567797184)\n",
            "(710, 0.01646432839334011)\n",
            "(720, 0.002913904143497348)\n",
            "(730, 0.0012028217315673828)\n",
            "(740, 0.013519358821213245)\n",
            "(750, 0.004005455877631903)\n",
            "(760, 0.002158260438591242)\n",
            "(770, 0.0588560588657856)\n",
            "Done Training\n",
            "('Epoch: ', 8, 'Train Loss: ', 0.010821977009956334, 'Test Loss: ', 0.04897221213999122, 'Accuracy: ', 98.21150855365474)\n",
            "(0, 0.003951025195419788)\n",
            "(10, 0.013099384494125843)\n",
            "(20, 0.0016391754616051912)\n",
            "(30, 0.005153465084731579)\n",
            "(40, 0.001361894654110074)\n",
            "(50, 0.002930116606876254)\n",
            "(60, 0.0032203197479248047)\n",
            "(70, 0.001085472060367465)\n",
            "(80, 0.0010444640647619963)\n",
            "(90, 0.0004909038543701172)\n",
            "(100, 0.011425971984863281)\n",
            "(110, 0.005971574690192938)\n",
            "(120, 0.00620768079534173)\n",
            "(130, 0.002273607300594449)\n",
            "(140, 0.030469775199890137)\n",
            "(150, 0.0008538722759112716)\n",
            "(160, 0.004854917526245117)\n",
            "(170, 0.012456655502319336)\n",
            "(180, 0.0028535842429846525)\n",
            "(190, 0.006584525108337402)\n",
            "(200, 0.0019016265869140625)\n",
            "(210, 0.003603768302127719)\n",
            "(220, 0.004095411393791437)\n",
            "(230, 0.00991668738424778)\n",
            "(240, 0.0031243800185620785)\n",
            "(250, 0.019042277708649635)\n",
            "(260, 0.002249002456665039)\n",
            "(270, 0.08847697079181671)\n",
            "(280, 0.0014386177062988281)\n",
            "(290, 0.015603589825332165)\n",
            "(300, 0.003554105758666992)\n",
            "(310, 0.002328205155208707)\n",
            "(320, 0.0039334772154688835)\n",
            "(330, 0.005319333169609308)\n",
            "(340, 0.015096592716872692)\n",
            "(350, 0.012895536608994007)\n",
            "(360, 0.000981664634309709)\n",
            "(370, 0.01640157774090767)\n",
            "(380, 0.16891634464263916)\n",
            "(390, 0.008506250567734241)\n",
            "(400, 0.02792646922171116)\n",
            "(410, 0.002283334732055664)\n",
            "(420, 0.013535809703171253)\n",
            "(430, 0.007894039154052734)\n",
            "(440, 0.0009177207830362022)\n",
            "(450, 0.0017741203773766756)\n",
            "(460, 0.0012059211730957031)\n",
            "(470, 0.0009907722705975175)\n",
            "(480, 0.007951617240905762)\n",
            "(490, 0.004919386003166437)\n",
            "(500, 0.03299691528081894)\n",
            "(510, 0.000645494437776506)\n",
            "(520, 0.006751441862434149)\n",
            "(530, 0.002756834030151367)\n",
            "(540, 0.002350711729377508)\n",
            "(550, 0.007045316509902477)\n",
            "(560, 0.004888200666755438)\n",
            "(570, 0.00503163319081068)\n",
            "(580, 0.023617815226316452)\n",
            "(590, 0.0026298523880541325)\n",
            "(600, 0.005055546760559082)\n",
            "(610, 0.00910029374063015)\n",
            "(620, 0.001087188720703125)\n",
            "(630, 0.0033943175803869963)\n",
            "(640, 0.00033016205998137593)\n",
            "(650, 0.03880057483911514)\n",
            "(660, 0.0017056942451745272)\n",
            "(670, 0.0018399000400677323)\n",
            "(680, 0.0026988028548657894)\n",
            "(690, 0.054743193089962006)\n",
            "(700, 0.0006547927623614669)\n",
            "(710, 0.042273472994565964)\n",
            "(720, 0.0018785953288897872)\n",
            "(730, 0.00836853962391615)\n",
            "(740, 0.004791378974914551)\n",
            "(750, 0.011810707859694958)\n",
            "(760, 0.018306206911802292)\n",
            "(770, 0.012340545654296875)\n",
            "Done Training\n",
            "('Epoch: ', 9, 'Train Loss: ', 0.009707189174675453, 'Test Loss: ', 0.04761369447343592, 'Accuracy: ', 98.41886988076723)\n",
            "('Saved model with accuracy: ', 98.41886988076723)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8su8aJguwS9q",
        "colab_type": "code",
        "outputId": "10b5d903-3faf-41c9-dc86-165e0928b89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "cell_type": "code",
      "source": [
        "list_epochs = [i+1 for i in range(10)]\n",
        "\n",
        "plt.plot(list_epochs,accuracy)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('AlexNet Accuracy vs. Epochs')\n",
        "plt.show()\n",
        "plt.plot(list_epochs,train_loss,label='Train Loss')\n",
        "plt.plot(list_epochs,test_loss,label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Test Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xwHSXx_qTqm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}